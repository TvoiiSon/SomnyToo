use std::sync::Arc;
use std::time::{Instant, Duration};
use std::collections::HashMap;
use tokio::sync::{mpsc, RwLock, Mutex, broadcast};
use bytes::Bytes;
use tracing::{info, error, debug, warn};
use dashmap::DashMap;

use crate::core::protocol::batch_system::config::BatchConfig;
use crate::core::protocol::batch_system::types::error::BatchError;
use crate::core::protocol::batch_system::types::priority::Priority;

// ‚úÖ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´
use crate::core::protocol::batch_system::optimized::work_stealing_dispatcher::{
    WorkStealingDispatcher, WorkStealingTask, WorkStealingResult, DispatcherAdvancedStats
};
use crate::core::protocol::batch_system::optimized::buffer_pool::OptimizedBufferPool;
use crate::core::protocol::batch_system::optimized::crypto_processor::OptimizedCryptoProcessor;
use crate::core::protocol::batch_system::optimized::factory::OptimizedFactory;

// ‚úÖ –ê–ö–°–ï–õ–ï–†–ê–¢–û–†–´
use crate::core::protocol::batch_system::acceleration_batch::chacha20_batch_accel::ChaCha20BatchAccelerator;
use crate::core::protocol::batch_system::acceleration_batch::blake3_batch_accel::Blake3BatchAccelerator;

// ‚úÖ –ò–ù–¢–ï–ì–†–ò–†–£–ï–ú–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´
use crate::core::protocol::batch_system::circuit_breaker::{
    CircuitBreakerManager, CircuitBreakerStats
};
use crate::core::protocol::batch_system::qos_manager::{QosManager, QosStatistics};
use crate::core::protocol::batch_system::adaptive_batcher::{
    AdaptiveBatcher, AdaptiveBatcherConfig, BatchMetrics
};
use crate::core::protocol::batch_system::metrics_tracing::{
    MetricsTracingSystem, MetricsConfig
};
use crate::core::protocol::batch_system::types::packet_types::{is_packet_supported, get_packet_info, get_packet_priority};

// ‚úÖ READER & WRITER
use crate::core::protocol::batch_system::core::reader::{BatchReader, ReaderEvent};
use crate::core::protocol::batch_system::core::writer::{BatchWriter};

// ‚úÖ –í–ù–ï–®–ù–ò–ï –ó–ê–í–ò–°–ò–ú–û–°–¢–ò
use crate::core::protocol::phantom_crypto::core::instance::PhantomCrypto;
use crate::core::protocol::server::session_manager_phantom::PhantomSessionManager;
use crate::core::protocol::packets::packet_service::PhantomPacketService;
use crate::core::protocol::phantom_crypto::packet::PhantomPacketProcessor;
use crate::core::monitoring::unified_monitor::UnifiedMonitor;

/// ‚ö° –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ô –£–ó–ï–õ BATCH –°–ò–°–¢–ï–ú–´ v2.1
/// –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—á–∞—è –≤–µ—Ä—Å–∏—è —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º
pub struct IntegratedBatchSystem {
    // üìã –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
    config: BatchConfig,

    // üîß –û–°–ù–û–í–ù–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´
    reader: Arc<BatchReader>,
    writer: Arc<BatchWriter>,
    work_stealing_dispatcher: Arc<WorkStealingDispatcher>,
    crypto_processor: Arc<OptimizedCryptoProcessor>,
    buffer_pool: Arc<OptimizedBufferPool>,

    // üöÄ –ê–ö–°–ï–õ–ï–†–ê–¢–û–†–´
    chacha20_accelerator: Arc<ChaCha20BatchAccelerator>,
    blake3_accelerator: Arc<Blake3BatchAccelerator>,

    // üõ°Ô∏è –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´
    circuit_breaker_manager: Arc<CircuitBreakerManager>,
    qos_manager: Arc<QosManager>,
    adaptive_batcher: Arc<AdaptiveBatcher>,
    metrics_tracing: Arc<MetricsTracingSystem>,

    // üåê –í–ù–ï–®–ù–ò–ï –°–ï–†–í–ò–°–´
    packet_service: Arc<PhantomPacketService>,
    packet_processor: PhantomPacketProcessor,
    session_manager: Arc<PhantomSessionManager>,
    crypto: Arc<PhantomCrypto>,

    // üì® –°–ò–°–¢–ï–ú–ù–´–ï –ö–ê–ù–ê–õ–´
    event_tx: mpsc::Sender<SystemEvent>,
    event_rx: Arc<Mutex<mpsc::Receiver<SystemEvent>>>,
    command_tx: broadcast::Sender<SystemCommand>,

    // üéÆ –£–ü–†–ê–í–õ–ï–ù–ò–ï
    is_running: Arc<std::sync::atomic::AtomicBool>,
    is_initialized: Arc<std::sync::atomic::AtomicBool>,
    startup_time: Instant,

    // üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò –ú–ï–¢–†–ò–ö–ò
    stats: Arc<RwLock<SystemStatistics>>,
    metrics: Arc<DashMap<String, MetricValue>>,

    // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –†–ï–ê–õ–¨–ù–û –ò–°–ü–û–õ–¨–ó–£–ï–ú–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´
    pending_batches: Arc<RwLock<Vec<PendingBatch>>>,
    active_connections: Arc<RwLock<HashMap<std::net::SocketAddr, ConnectionInfo>>>,
    session_cache: Arc<RwLock<HashMap<Vec<u8>, SessionCacheEntry>>>,
    scaling_settings: Arc<RwLock<ScalingSettings>>,
    performance_counters: Arc<DashMap<String, PerformanceCounter>>,

    // üÜï –ù–û–í–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´ –î–õ–Ø –î–ò–ù–ê–ú–ò–ß–ï–°–ö–û–ì–û –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–Ø
    worker_pool: Arc<WorkerPool>,
    scaling_lock: Arc<Mutex<()>>,
}

/// üè≠ –ü—É–ª –≤–æ—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
struct WorkerPool {
    min_workers: usize,
    max_workers: usize,
    current_workers: Arc<std::sync::atomic::AtomicUsize>,
    worker_handles: Arc<Mutex<Vec<tokio::task::JoinHandle<()>>>>,
    shutdown_tx: broadcast::Sender<()>,
}

impl WorkerPool {
    fn new(min_workers: usize, max_workers: usize) -> Self {
        let (shutdown_tx, _) = broadcast::channel(max_workers * 2);
        Self {
            min_workers,
            max_workers,
            current_workers: Arc::new(std::sync::atomic::AtomicUsize::new(min_workers)),
            worker_handles: Arc::new(Mutex::new(Vec::new())),
            shutdown_tx,
        }
    }

    async fn add_workers(&self, count: usize, _dispatcher: Arc<WorkStealingDispatcher>) -> Result<usize, BatchError> {
        let current = self.current_workers.load(std::sync::atomic::Ordering::SeqCst);
        let target = (current + count).min(self.max_workers);
        let to_add = target - current;

        if to_add == 0 {
            return Ok(0);
        }

        let mut handles = self.worker_handles.lock().await;
        let shutdown_rx = self.shutdown_tx.subscribe();

        for i in 0..to_add {
            let worker_id = current + i;
            let mut shutdown_rx = shutdown_rx.resubscribe();

            let handle = tokio::spawn(async move {
                loop {
                    tokio::select! {
                        _ = shutdown_rx.recv() => {
                            debug!("üëã Dynamic worker #{} shutting down", worker_id);
                            break;
                        }
                        _ = tokio::time::sleep(Duration::from_millis(100)) => {
                            // Worker –±—É–¥–µ—Ç –ø–æ–ª—É—á–∞—Ç—å –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ –¥–∏—Å–ø–µ—Ç—á–µ—Ä
                        }
                    }
                }
            });

            handles.push(handle);
        }

        self.current_workers.store(target, std::sync::atomic::Ordering::SeqCst);
        Ok(to_add)
    }

    async fn remove_workers(&self, count: usize) -> Result<usize, BatchError> {
        let current = self.current_workers.load(std::sync::atomic::Ordering::SeqCst);
        let target = current.saturating_sub(count).max(self.min_workers);
        let to_remove = current - target;

        if to_remove == 0 {
            return Ok(0);
        }

        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –¥–ª—è to_remove –≤–æ—Ä–∫–µ—Ä–æ–≤
        for _ in 0..to_remove {
            let _ = self.shutdown_tx.send(());
        }

        self.current_workers.store(target, std::sync::atomic::Ordering::SeqCst);
        Ok(to_remove)
    }
}

impl IntegratedBatchSystem {
    /// üöÄ –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π batch —Å–∏—Å—Ç–µ–º—ã
    pub async fn new(
        config: BatchConfig,
        session_manager: Arc<PhantomSessionManager>,
        crypto: Arc<PhantomCrypto>,
        monitor: Option<Arc<UnifiedMonitor>>,
    ) -> Result<Self, BatchError> {
        let startup_time = Instant::now();

        // ============= 1. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø METRICS TRACING =============
        info!("üìä [1/11] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Metrics & Tracing...");
        let metrics_config = MetricsConfig {
            enabled: config.metrics_enabled,
            collection_interval: config.metrics_collection_interval,
            trace_sampling_rate: config.trace_sampling_rate,
            service_name: "batch-system".to_string(),
            service_version: "2.1.0".to_string(),
            environment: "production".to_string(),
            retention_period: Duration::from_secs(3600),
        };

        let metrics_tracing = Arc::new(
            MetricsTracingSystem::new(metrics_config)
                .map_err(|e| BatchError::ProcessingError(format!("Metrics init failed: {}", e)))?
        );

        // ============= 2. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø CIRCUIT BREAKER =============
        info!("üõ°Ô∏è [2/11] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Circuit Breaker Manager...");
        let circuit_breaker_manager = Arc::new(
            CircuitBreakerManager::new(Arc::new(config.clone()))
        );

        let dispatcher_circuit_breaker = circuit_breaker_manager.get_or_create("dispatcher");

        // ============= 3. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø QoS =============
        info!("‚öñÔ∏è [3/11] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è QoS Manager...");
        let qos_manager = Arc::new(
            QosManager::new(
                config.high_priority_quota,
                config.normal_priority_quota,
                config.low_priority_quota,
                config.max_queue_size,
            )
        );

        // ============= 4. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ADAPTIVE BATCHER =============
        info!("üîÑ [4/11] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Adaptive Batcher —Å ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º...");
        let adaptive_batcher_config = AdaptiveBatcherConfig {
            min_batch_size: config.min_batch_size,
            max_batch_size: config.max_batch_size,
            initial_batch_size: config.batch_size,
            window_duration: config.adaptive_batch_window,
            target_latency: Duration::from_millis(50),
            max_increase_rate: 0.5,
            min_decrease_rate: 0.3,
            adaptation_interval: Duration::from_secs(1),
            enable_auto_tuning: config.enable_adaptive_batching,
            enable_predictive_adaptation: true,
            prediction_horizon: Duration::from_secs(30),
            smoothing_factor: 0.3,
            confidence_threshold: 0.7,
        };

        let adaptive_batcher = Arc::new(
            AdaptiveBatcher::new(adaptive_batcher_config)
        );

        // ============= 5. –ö–ê–ù–ê–õ–´ –°–û–ë–´–¢–ò–ô =============
        info!("üì¨ [5/11] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–Ω–∞–ª–æ–≤ —Å–æ–±—ã—Ç–∏–π...");
        let (system_event_tx, system_event_rx) = mpsc::channel(50000);
        let (command_tx, _) = broadcast::channel(1000);
        let (reader_event_tx, reader_event_rx) = mpsc::channel(50000);

        // ============= 6. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–• –ö–û–ú–ü–û–ù–ï–ù–¢–û–í =============
        info!("üîß [6/11] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...");

        let buffer_pool = OptimizedFactory::create_buffer_pool(
            config.read_buffer_size,
            config.write_buffer_size,
            64 * 1024,
            5000,
        );

        let crypto_processor = OptimizedFactory::create_crypto_processor(
            config.worker_count * 2
        );

        // ============= 7. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø SIMD –ê–ö–°–ï–õ–ï–†–ê–¢–û–†–û–í =============
        info!("üöÄ [7/11] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SIMD –∞–∫—Å–µ–ª–µ—Ä–∞—Ç–æ—Ä–æ–≤...");
        let chacha20_accelerator = Arc::new(
            ChaCha20BatchAccelerator::new(config.simd_batch_size)
        );
        let blake3_accelerator = Arc::new(
            Blake3BatchAccelerator::new(config.simd_batch_size)
        );

        // ============= 8. –í–ù–ï–®–ù–ò–ï –°–ï–†–í–ò–°–´ =============
        info!("üåê [8/11] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–Ω–µ—à–Ω–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤...");
        let packet_service = Arc::new(PhantomPacketService::new(
            session_manager.clone(),
            {
                use crate::core::protocol::server::heartbeat::types::ConnectionHeartbeatManager;

                let monitor_to_use = monitor.unwrap_or_else(|| {
                    Arc::new(UnifiedMonitor::new(
                        crate::core::monitoring::config::MonitoringConfig::default()
                    ))
                });

                Arc::new(ConnectionHeartbeatManager::new(
                    session_manager.clone(),
                    monitor_to_use,
                ))
            },
        ));

        let packet_processor = PhantomPacketProcessor::new();

        // ============= 9. READER & WRITER =============
        info!("üìñ [9/11] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Reader/Writer...");
        let reader = Arc::new(BatchReader::new(config.clone(), reader_event_tx.clone()));
        let writer = Arc::new(BatchWriter::new(config.clone()));

        let work_stealing_dispatcher = OptimizedFactory::create_dispatcher(
            config.worker_count,
            config.max_queue_size,
            session_manager.clone(),
            adaptive_batcher.clone(),
            qos_manager.clone(),
            dispatcher_circuit_breaker,
        );

        // ============= 10. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø WORKER POOL =============
        info!("üè≠ [10/11] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Worker Pool –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è...");
        let worker_pool = Arc::new(WorkerPool::new(
            config.worker_count / 2,
            config.worker_count * 4,
        ));

        // ============= 11. –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–ë–û–†–ö–ê =============
        info!("üèóÔ∏è [11/11] –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã...");

        let system = Self {
            config: config.clone(),
            reader,
            writer,
            work_stealing_dispatcher,
            crypto_processor,
            buffer_pool,
            chacha20_accelerator,
            blake3_accelerator,
            circuit_breaker_manager,
            qos_manager,
            adaptive_batcher,
            metrics_tracing,
            packet_service,
            packet_processor,
            session_manager: session_manager.clone(),
            crypto: crypto.clone(),
            event_tx: system_event_tx.clone(),
            event_rx: Arc::new(Mutex::new(system_event_rx)),
            command_tx,
            is_running: Arc::new(std::sync::atomic::AtomicBool::new(true)),
            is_initialized: Arc::new(std::sync::atomic::AtomicBool::new(false)),
            startup_time,
            stats: Arc::new(RwLock::new(SystemStatistics {
                startup_time,
                ..Default::default()
            })),
            metrics: Arc::new(DashMap::new()),
            pending_batches: Arc::new(RwLock::new(Vec::with_capacity(1000))),
            active_connections: Arc::new(RwLock::new(HashMap::with_capacity(10000))),
            session_cache: Arc::new(RwLock::new(HashMap::with_capacity(10000))),
            scaling_settings: Arc::new(RwLock::new(ScalingSettings::default())),
            performance_counters: Arc::new(DashMap::new()),
            worker_pool,
            scaling_lock: Arc::new(Mutex::new(())),
        };

        // ============= –ó–ê–ü–£–°–ö –ö–û–ú–ü–û–ù–ï–ù–¢–û–í =============
        system.start_reader_event_converter(reader_event_rx).await;
        system.start_session_cache_cleaner().await;
        system.start_performance_counter_updater().await;
        system.initialize().await?;

        Ok(system)
    }

    /// üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä —Å–æ–±—ã—Ç–∏–π Reader -> System
    async fn start_reader_event_converter(&self, mut reader_event_rx: mpsc::Receiver<ReaderEvent>) {
        let event_tx = self.event_tx.clone();
        let is_running = self.is_running.clone();

        tokio::spawn(async move {
            debug!("üîÑ Reader event converter started");

            while is_running.load(std::sync::atomic::Ordering::Relaxed) {
                match reader_event_rx.recv().await {
                    Some(event) => {
                        let system_event = match event {
                            ReaderEvent::DataReady { session_id, data, source_addr, priority, received_at } => {
                                SystemEvent::DataReceived {
                                    session_id,
                                    data: data.freeze(),
                                    source_addr,
                                    priority,
                                    timestamp: received_at,
                                }
                            }
                            ReaderEvent::ConnectionClosed { source_addr, reason } => {
                                SystemEvent::ConnectionClosed {
                                    addr: source_addr,
                                    session_id: Vec::new(),
                                    reason,
                                }
                            }
                            ReaderEvent::Error { source_addr: _, error } => {
                                SystemEvent::ErrorOccurred {
                                    error: error.to_string(),
                                    context: "reader_error".to_string(),
                                    severity: ErrorSeverity::High,
                                }
                            }
                        };

                        if let Err(e) = event_tx.send(system_event).await {
                            error!("‚ùå Failed to send converted event: {}", e);
                            break;
                        }
                    }
                    None => {
                        debug!("üì≠ Reader event channel closed");
                        break;
                    }
                }
            }

            debug!("üëã Reader event converter stopped");
        });
    }

    /// üßπ –û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π –≤ –∫—ç—à–µ —Å–µ—Å—Å–∏–π
    async fn start_session_cache_cleaner(&self) {
        let session_cache = self.session_cache.clone();
        let is_running = self.is_running.clone();

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(300)); // 5 –º–∏–Ω—É—Ç

            while is_running.load(std::sync::atomic::Ordering::Relaxed) {
                interval.tick().await;

                let mut cache = session_cache.write().await;
                let before = cache.len();
                let now = Instant::now();

                cache.retain(|_, entry| {
                    now.duration_since(entry.last_used) < Duration::from_secs(3600) // 1 —á–∞—Å
                });

                let removed = before - cache.len();
                if removed > 0 {
                    debug!("üßπ Session cache cleaned: removed {} stale entries", removed);
                }
            }
        });
    }

    /// üìä –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    async fn start_performance_counter_updater(&self) {
        let perf_counters = self.performance_counters.clone();
        let is_running = self.is_running.clone();
        let system = self.clone();

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(10));

            while is_running.load(std::sync::atomic::Ordering::Relaxed) {
                interval.tick().await;

                // –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                let stats = system.stats.read().await;

                let mut throughput_counter = perf_counters
                    .entry("throughput".to_string())
                    .or_insert_with(|| PerformanceCounter::new("throughput".to_string(), 60));

                let uptime = stats.uptime.as_secs_f64().max(1.0);
                let throughput = stats.total_packets_processed as f64 / uptime;
                throughput_counter.update(throughput);

                let mut latency_counter = perf_counters
                    .entry("avg_latency_ms".to_string())
                    .or_insert_with(|| PerformanceCounter::new("avg_latency_ms".to_string(), 60));

                latency_counter.update(stats.avg_processing_time.as_millis() as f64);

                let mut batch_size_counter = perf_counters
                    .entry("avg_batch_size".to_string())
                    .or_insert_with(|| PerformanceCounter::new("avg_batch_size".to_string(), 60));

                batch_size_counter.update(system.adaptive_batcher.get_metrics().await.avg_batch_size);

                debug!("üìä Performance counters updated");
            }
        });
    }

    /// üéØ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
    async fn initialize(&self) -> Result<(), BatchError> {
        info!("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã...");

        self.is_initialized.store(true, std::sync::atomic::Ordering::SeqCst);

        self.start_event_handlers().await;
        self.start_command_handlers().await;
        self.start_statistics_collector().await;
        self.start_batch_processor().await;
        self.start_performance_monitoring().await;
        self.start_auto_scaling().await;
        self.start_qos_adaptation().await;

        info!("‚úÖ –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã");
        Ok(())
    }

    /// üëÇ –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Å–æ–±—ã—Ç–∏–π
    async fn start_event_handlers(&self) {
        let event_rx = self.event_rx.clone();
        let system = self.clone();

        tokio::spawn(async move {
            debug!("üëÇ Event handler started");
            let mut receiver = event_rx.lock().await;

            while let Some(event) = receiver.recv().await {
                system.handle_event(event).await;
            }

            debug!("üëã Event handler stopped");
        });
    }

    /// üéõÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏–π
    async fn handle_event(&self, event: SystemEvent) {
        match event {
            SystemEvent::DataReceived { session_id, data, source_addr, priority, timestamp } => {
                self.handle_data_received(session_id, data, source_addr, priority, timestamp).await;
            }
            SystemEvent::DataProcessed { session_id, result, processing_time, worker_id } => {
                self.handle_data_processed(session_id, result, processing_time, worker_id).await;
            }
            SystemEvent::ConnectionOpened { addr, session_id } => {
                self.handle_connection_opened(addr, session_id).await;
            }
            SystemEvent::ConnectionClosed { addr, session_id, reason } => {
                self.handle_connection_closed(addr, session_id, reason).await;
            }
            SystemEvent::BatchCompleted { batch_id, size, processing_time, success_rate } => {
                self.handle_batch_completed(batch_id, size, processing_time, success_rate).await;
            }
            SystemEvent::ErrorOccurred { error, context, severity } => {
                self.handle_error_occurred(error, context, severity).await;
            }
        }
    }

    /// üì• –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    async fn handle_data_received(
        &self,
        session_id: Vec<u8>,
        data: Bytes,
        source_addr: std::net::SocketAddr,
        _priority: Priority,  // –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Å–ª–µ –¥–µ—à–∏—Ñ—Ä–æ–≤–∫–∏
        timestamp: Instant,
    ) {
        debug!("üì• Raw data received: {} bytes from {}", data.len(), source_addr);

        // –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        {
            let mut stats = self.stats.write().await;
            stats.total_data_received += data.len() as u64;
        }

        // ‚úÖ –ù–ï –ü–†–û–í–ï–†–Ø–ï–ú –¢–ò–ü –ü–ê–ö–ï–¢–ê –ó–î–ï–°–¨!
        // –¢–∏–ø –ø–∞–∫–µ—Ç–∞ –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ü–û–°–õ–ï –¥–µ—à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è –≤ worker'–µ

        let task = WorkStealingTask {
            id: 0,
            session_id: session_id.clone(),
            data: data.clone(),
            source_addr,
            priority: Priority::Normal, // –í—Ä–µ–º–µ–Ω–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, —Ä–µ–∞–ª—å–Ω—ã–π –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—Å—è –ø–æ—Å–ª–µ –¥–µ—à–∏—Ñ—Ä–æ–≤–∫–∏
            created_at: timestamp,
            worker_id: None,
            retry_count: 0,
            deadline: Some(timestamp + Duration::from_secs(30)),
        };

        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –¥–∏—Å–ø–µ—Ç—á–µ—Ä
        match self.work_stealing_dispatcher.submit_task(task).await {
            Ok(task_id) => {
                debug!("‚úÖ Task {} submitted to dispatcher", task_id);
                self.track_task_result(task_id, session_id, source_addr).await;
            }
            Err(e) => {
                error!("‚ùå Failed to submit task: {}", e);
                self.record_metric("dispatcher.rejections", 1.0).await;

                let event = SystemEvent::ErrorOccurred {
                    error: e.to_string(),
                    context: "submit_task".to_string(),
                    severity: ErrorSeverity::High,
                };
                let _ = self.event_tx.send(event).await;
            }
        }
    }

    /// üîç –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∑–∞–¥–∞—á–∏
    async fn track_task_result(
        &self,
        task_id: u64,
        session_id: Vec<u8>,
        source_addr: std::net::SocketAddr,
    ) {
        let dispatcher = self.work_stealing_dispatcher.clone();
        let event_tx = self.event_tx.clone();
        let system = self.clone();

        tokio::spawn(async move {
            let result = tokio::time::timeout(
                Duration::from_secs(30),
                async {
                    let mut attempts = 0;
                    while attempts < 100 {
                        if let Some(task_result) = dispatcher.get_result(task_id) {
                            return Some(task_result);
                        }
                        tokio::time::sleep(Duration::from_millis(100)).await;
                        attempts += 1;
                    }
                    None
                }
            ).await;

            match result {
                Ok(Some(task_result)) => {
                    debug!("‚úÖ Task {} completed", task_id);

                    {
                        let mut stats = system.stats.write().await;
                        stats.work_stealing_count = dispatcher.get_stats()
                            .get("work_steals")
                            .copied()
                            .unwrap_or(0);
                    }

                    let process_result = ProcessResult {
                        success: task_result.result.is_ok(),
                        data: task_result.result.clone().ok().map(Bytes::from),
                        error: task_result.result.clone().err().map(|e| e.to_string()),
                        metadata: HashMap::from([
                            ("worker_id".to_string(), task_result.worker_id.to_string()),
                            ("processing_time".to_string(), format!("{:?}", task_result.processing_time)),
                        ]),
                    };

                    let event = SystemEvent::DataProcessed {
                        session_id: session_id.clone(),
                        result: process_result,
                        processing_time: task_result.processing_time,
                        worker_id: Some(task_result.worker_id),
                    };

                    let _ = event_tx.send(event).await;
                    system.process_task_result(task_result, session_id, source_addr).await;
                }
                Ok(None) => {
                    warn!("‚ö†Ô∏è Task {} result timeout", task_id);
                }
                Err(_) => {
                    error!("‚è∞ Task {} timeout", task_id);
                }
            }
        });
    }

    /// üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∑–∞–¥–∞—á–∏
    async fn process_task_result(
        &self,
        task_result: WorkStealingResult,
        _session_id: Vec<u8>,
        _source_addr: std::net::SocketAddr,
    ) {
        match task_result.result {
            Ok(data) => {
                if data.len() > 1 {
                    let packet_type = data[0];
                    let packet_data = &data[1..];

                    if let Some(session) = self.session_manager.get_session(&task_result.session_id).await {
                        // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–∞–∫–µ—Ç –≤ packet_service –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                        match self.packet_service.process_packet(
                            session.clone(),
                            packet_type,
                            packet_data.to_vec(),
                            task_result.destination_addr,
                        ).await {
                            Ok(processing_result) => {
                                // ‚úÖ packet_service —É–∂–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
                                match self.packet_processor.create_outgoing_vec(
                                    &session,
                                    processing_result.packet_type,  // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∏–ø –∏–∑ processing_result
                                    &processing_result.response,    // –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–≤–µ—Ç –∏–∑ packet_service
                                ) {
                                    Ok(encrypted_response) => {
                                        if let Err(e) = self.writer.write(
                                            task_result.destination_addr,
                                            task_result.session_id.clone(),
                                            Bytes::from(encrypted_response),
                                            processing_result.priority,  // –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏–∑ packet_service
                                            true,  // requires_flush –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–∞–∫–µ—Ç–æ–≤
                                        ).await {
                                            error!("‚ùå Failed to send response: {}", e);
                                        } else {
                                            debug!("‚úÖ Response sent for packet type 0x{:02x}", packet_type);
                                        }
                                    }
                                    Err(e) => error!("‚ùå Encryption failed: {}", e),
                                }
                            }
                            Err(e) => error!("‚ùå Packet processing failed: {}", e),
                        }
                    }
                }
            }
            Err(e) => error!("‚ùå Task processing failed: {}", e),
        }
    }

    /// üîó –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    async fn handle_connection_opened(&self, addr: std::net::SocketAddr, session_id: Vec<u8>) {
        debug!("üîó Connection opened: {} -> {}", addr, hex::encode(&session_id));

        let mut connections = self.active_connections.write().await;
        connections.insert(addr, ConnectionInfo {
            addr,
            session_id: session_id.clone(),
            opened_at: Instant::now(),
            last_activity: Instant::now(),
            bytes_received: 0,
            bytes_sent: 0,
            priority: Priority::Normal,
            is_active: true,
            worker_assigned: None,
        });

        let mut stats = self.stats.write().await;
        stats.total_connections += 1;
    }

    /// üîí –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    async fn handle_connection_closed(&self, addr: std::net::SocketAddr, session_id: Vec<u8>, reason: String) {
        debug!("üîí Connection closed: {} -> {}: {}", addr, hex::encode(&session_id), reason);

        let mut connections = self.active_connections.write().await;
        connections.remove(&addr);
    }

    /// ‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –±–∞—Ç—á–∞
    async fn handle_batch_completed(
        &self,
        batch_id: u64,
        size: usize,
        processing_time: Duration,
        success_rate: f64
    ) {
        debug!("‚úÖ Batch {} completed: size={}, time={:?}, success={:.1}%",
               batch_id, size, processing_time, success_rate * 100.0);

        let mut stats = self.stats.write().await;
        stats.total_batches_processed += 1;

        let total_batches = stats.total_batches_processed as f64;
        let current_avg = stats.avg_processing_time.as_nanos() as f64;
        let new_avg = (current_avg * (total_batches - 1.0) + processing_time.as_nanos() as f64) / total_batches;
        stats.avg_processing_time = Duration::from_nanos(new_avg as u64);

        let throughput = size as f64 / processing_time.as_secs_f64().max(0.001);
        if throughput > stats.peak_throughput {
            stats.peak_throughput = throughput;
        }
    }

    /// ‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏
    async fn handle_error_occurred(&self, error: String, context: String, severity: ErrorSeverity) {
        match severity {
            ErrorSeverity::Low => debug!("‚ö†Ô∏è Low: {} in {}", error, context),
            ErrorSeverity::Medium => warn!("‚ö†Ô∏è Medium: {} in {}", error, context),
            ErrorSeverity::High => error!("‚ùå High: {} in {}", error, context),
            ErrorSeverity::Critical => {
                error!("üö® CRITICAL: {} in {}", error, context);
            }
        }

        let mut stats = self.stats.write().await;
        stats.total_errors += 1;

        self.record_metric("system.errors", 1.0).await;
        self.record_metric(&format!("system.errors.{}", severity as u8), 1.0).await;
    }

    /// üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    async fn handle_data_processed(
        &self,
        session_id: Vec<u8>,
        result: ProcessResult,
        _processing_time: Duration,
        _worker_id: Option<usize>,
    ) {
        if result.success {
            if let Some(data) = &result.data {
                let mut stats = self.stats.write().await;
                stats.total_data_sent += data.len() as u64;

                if let Some(addr) = result.metadata.get("destination_addr") {
                    if let Ok(addr) = addr.parse() {
                        let mut connections = self.active_connections.write().await;
                        if let Some(conn) = connections.get_mut(&addr) {
                            conn.bytes_sent += data.len() as u64;
                            conn.last_activity = Instant::now();
                        }
                    }
                }
            }
        }

        let mut cache = self.session_cache.write().await;
        if let Some(entry) = cache.get_mut(&session_id) {
            entry.last_used = Instant::now();
            entry.access_count += 1;
        }
    }

    /// üìà –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    async fn start_performance_monitoring(&self) {
        let system = self.clone();

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(5));

            while system.is_running.load(std::sync::atomic::Ordering::Relaxed) {
                interval.tick().await;
                system.update_performance_counters().await;
                system.check_scaling_needs().await;
            }
        });
    }

    /// üìä –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    async fn update_performance_counters(&self) {
        // –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±—É—Ñ–µ—Ä–Ω–æ–≥–æ –ø—É–ª–∞
        let buffer_stats = self.buffer_pool.get_detailed_stats();
        let total_hit_rate = buffer_stats.get("Global")
            .map(|s| s.hit_rate)
            .unwrap_or(0.0);

        self.record_metric("buffer_pool.hit_rate", total_hit_rate).await;
        self.record_metric("buffer_pool.reuse_rate", self.buffer_pool.get_reuse_rate()).await;

        // –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—Ä–∏–ø—Ç–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        let crypto_stats = self.crypto_processor.get_stats();
        let crypto_tasks = crypto_stats.get("crypto_tasks_submitted").copied().unwrap_or(0);
        let crypto_processed = crypto_stats.get("crypto_tasks_processed").copied().unwrap_or(0);
        let crypto_steals = crypto_stats.get("crypto_steals").copied().unwrap_or(0);

        self.record_metric("crypto.tasks_submitted", crypto_tasks as f64).await;
        self.record_metric("crypto.tasks_processed", crypto_processed as f64).await;
        self.record_metric("crypto.steals", crypto_steals as f64).await;

        // –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
        let dispatcher_stats = self.work_stealing_dispatcher.get_advanced_stats().await;
        self.record_metric("dispatcher.tasks_processed", dispatcher_stats.total_tasks_processed as f64).await;
        self.record_metric("dispatcher.work_steals", dispatcher_stats.work_steals as f64).await;
        self.record_metric("dispatcher.imbalance", dispatcher_stats.imbalance).await;

        {
            let mut stats = self.stats.write().await;
            stats.work_stealing_count = dispatcher_stats.work_steals;
            stats.buffer_hit_rate = total_hit_rate;
        }

        // –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        let connections = self.active_connections.read().await.len();
        self.record_metric("connections.active", connections as f64).await;
    }

    /// üìà –ó–ê–ü–£–°–ö –ê–í–¢–û–°–ö–ï–ô–õ–ò–ù–ì–ê
    async fn start_auto_scaling(&self) {
        let system = self.clone();

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(30));

            while system.is_running.load(std::sync::atomic::Ordering::Relaxed) {
                interval.tick().await;

                let settings = system.scaling_settings.read().await;
                if !settings.auto_scaling_enabled {
                    continue;
                }

                let now = Instant::now();
                if now.duration_since(settings.last_scaling_time) < Duration::from_secs(settings.scaling_cooldown_seconds) {
                    continue;
                }

                drop(settings);

                system.perform_auto_scaling().await;
            }
        });
    }

    /// üîÑ –í–´–ü–û–õ–ù–ï–ù–ò–ï –ê–í–¢–û–°–ö–ï–ô–õ–ò–ù–ì–ê
    async fn perform_auto_scaling(&self) {
        let _lock = self.scaling_lock.lock().await;

        let settings = self.scaling_settings.read().await;
        let dispatcher_stats = self.work_stealing_dispatcher.get_advanced_stats().await;
        let current_workers = self.worker_pool.current_workers.load(std::sync::atomic::Ordering::SeqCst);

        // –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –≤–≤–µ—Ä—Ö
        let should_scale_up =
            dispatcher_stats.queue_backlog > settings.work_stealing_target_queue_size * 2 ||
                dispatcher_stats.imbalance > 0.7 ||
                dispatcher_stats.avg_processing_time_ms > 100.0 ||
                self.active_connections.read().await.len() as f64 > settings.connection_target_count as f64 * 0.8;

        // –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –≤–Ω–∏–∑
        let should_scale_down =
            dispatcher_stats.queue_backlog < settings.work_stealing_target_queue_size / 4 &&
                dispatcher_stats.imbalance < 0.2 &&
                dispatcher_stats.avg_processing_time_ms < 20.0 &&
                current_workers > settings.min_worker_count;

        if should_scale_up && current_workers < settings.max_worker_count {
            let scale_up_by = 2.min(settings.max_worker_count - current_workers);
            info!("üìà Auto-scaling: scaling UP by {} workers (current: {}, queue: {})",
                scale_up_by, current_workers, dispatcher_stats.queue_backlog);
            let _ = self.scale_up(scale_up_by).await;
        } else if should_scale_down && current_workers > settings.min_worker_count {
            let scale_down_by = 2.min(current_workers - settings.min_worker_count);
            info!("üìâ Auto-scaling: scaling DOWN by {} workers (current: {}, queue: {})",
                scale_down_by, current_workers, dispatcher_stats.queue_backlog);
            let _ = self.scale_down(scale_down_by).await;
        }
    }

    /// üîÑ –ó–∞–ø—É—Å–∫ QoS –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
    async fn start_qos_adaptation(&self) {
        let qos_manager = self.qos_manager.clone();

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(30));

            loop {
                interval.tick().await;

                match qos_manager.adapt_quotas().await {
                    Ok(decision) => {
                        info!("üîÑ QoS adapted: {}", decision.reason);
                    }
                    Err(e) => {
                        debug!("QoS adaptation skipped: {}", e);
                    }
                }
            }
        });
    }

    /// üìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Å–∫–µ–π–ª–∏–Ω–≥–∞
    async fn check_scaling_needs(&self) {
        let settings = self.scaling_settings.read().await;

        let buffer_hit_rate = self.get_metric("buffer_pool.hit_rate").await.unwrap_or(0.0);
        let crypto_success_rate = self.get_metric("crypto.success_rate").await.unwrap_or(1.0);
        let dispatcher_load = self.get_metric("dispatcher.imbalance").await.unwrap_or(0.0);
        let active_connections = self.active_connections.read().await.len();
        let current_workers = self.worker_pool.current_workers.load(std::sync::atomic::Ordering::SeqCst);

        if buffer_hit_rate < settings.buffer_pool_target_hit_rate * 0.8 {
            warn!("üìâ Buffer pool hit rate low: {:.1}%", buffer_hit_rate * 100.0);
            let _ = self.buffer_pool.force_cleanup();
        }

        if crypto_success_rate < settings.crypto_processor_target_success_rate * 0.9 {
            warn!("‚ö†Ô∏è Crypto success rate low: {:.1}%", crypto_success_rate * 100.0);
            if let Some(cb) = self.circuit_breaker_manager.get_breaker("crypto_processor").await {
                cb.reset().await;
            }
        }

        if dispatcher_load > 0.7 {
            warn!("‚öñÔ∏è High dispatcher imbalance: {:.2}", dispatcher_load);
            self.rebalance_workers().await;
        }

        if active_connections as f64 > settings.connection_target_count as f64 * 1.5 {
            warn!("üîå High connection count: {}", active_connections);
            if current_workers < settings.max_worker_count {
                let _ = self.scale_up(2).await;
            }
        }
    }

    /// üéõÔ∏è –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫–æ–º–∞–Ω–¥
    async fn start_command_handlers(&self) {
        let command_rx = self.command_tx.subscribe();
        let system = self.clone();

        tokio::spawn(async move {
            debug!("üéõÔ∏è Command handler started");
            let mut receiver = command_rx;

            while let Ok(command) = receiver.recv().await {
                system.handle_command(command).await;
            }

            debug!("üëã Command handler stopped");
        });
    }

    /// üéÆ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã
    async fn handle_command(&self, command: SystemCommand) {
        match command {
            SystemCommand::StartProcessing => self.start_processing().await,
            SystemCommand::PauseProcessing => self.pause_processing().await,
            SystemCommand::ResumeProcessing => self.resume_processing().await,
            SystemCommand::StopProcessing => self.stop_processing().await,
            SystemCommand::FlushBuffers => self.flush_buffers().await,
            SystemCommand::ClearCaches => self.clear_caches().await,
            SystemCommand::AdjustConfig { parameter, value } => self.adjust_config(parameter, value).await,
            SystemCommand::EmergencyShutdown { reason } => self.emergency_shutdown(reason).await,
            SystemCommand::GetStatistics => self.get_statistics().await,
            SystemCommand::ResetStatistics => self.reset_statistics().await,
            SystemCommand::RebalanceWorkers => self.rebalance_workers().await,
            SystemCommand::ScaleUp { count } => {
                let _ = self.scale_up(count).await;
            }
            SystemCommand::ScaleDown { count } => {
                let _ = self.scale_down(count).await;
            }
            SystemCommand::UpdateScalingSettings { settings } => self.update_scaling_settings(settings).await,
        }
    }

    /// ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    async fn start_processing(&self) {
        if !self.is_running.load(std::sync::atomic::Ordering::SeqCst) {
            info!("‚ñ∂Ô∏è Starting data processing...");
            self.is_running.store(true, std::sync::atomic::Ordering::SeqCst);
        }
    }

    /// ‚è∏Ô∏è –ü–∞—É–∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    async fn pause_processing(&self) {
        if self.is_running.load(std::sync::atomic::Ordering::SeqCst) {
            info!("‚è∏Ô∏è Pausing data processing...");
            self.is_running.store(false, std::sync::atomic::Ordering::SeqCst);
        }
    }

    /// ‚ñ∂Ô∏è –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    async fn resume_processing(&self) {
        self.start_processing().await;
    }

    /// ‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    async fn stop_processing(&self) {
        info!("‚èπÔ∏è Stopping data processing...");
        self.is_running.store(false, std::sync::atomic::Ordering::SeqCst);
        self.shutdown_components().await;
    }

    /// üåÄ –°–±—Ä–æ—Å –±—É—Ñ–µ—Ä–æ–≤
    async fn flush_buffers(&self) {
        info!("üåÄ Flushing all buffers...");
        let _ = self.buffer_pool.force_cleanup();

        let mut cache = self.session_cache.write().await;
        cache.clear();
    }

    /// üßπ –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–µ–π
    async fn clear_caches(&self) {
        info!("üßπ Clearing all caches...");

        let mut session_cache = self.session_cache.write().await;
        session_cache.clear();

        let mut connections = self.active_connections.write().await;
        connections.clear();

        self.performance_counters.clear();
        self.metrics.clear();

        let mut pending = self.pending_batches.write().await;
        pending.clear();

        info!("‚úÖ All caches cleared");
    }

    /// ‚öôÔ∏è –†–ï–ì–£–õ–ò–†–û–í–ö–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò
    async fn adjust_config(&self, parameter: String, value: String) {
        info!("‚öôÔ∏è Adjusting config: {} = {}", parameter, value);

        match parameter.as_str() {
            "batch_size" => {
                if let Ok(size) = value.parse::<usize>() {
                    let mut config = self.adaptive_batcher.config.clone();
                    let clamped_size = size.clamp(config.min_batch_size, config.max_batch_size);
                    config.initial_batch_size = clamped_size;

                    *self.adaptive_batcher.current_batch_size.write().await = clamped_size;

                    self.record_metric("config.batch_size", clamped_size as f64).await;
                    info!("‚úÖ Batch size updated to {} (clamped to {}-{})",
                        clamped_size, config.min_batch_size, config.max_batch_size);
                }
            }
            "worker_count" => {
                if let Ok(count) = value.parse::<usize>() {
                    let current_workers = self.worker_pool.current_workers.load(std::sync::atomic::Ordering::SeqCst);
                    let settings = self.scaling_settings.read().await;

                    if count > current_workers {
                        if count <= settings.max_worker_count {
                            let increase = count - current_workers;
                            info!("üìà Increasing worker count by {} to {}", increase, count);
                            let _ = self.scale_up(increase).await;
                        } else {
                            warn!("Requested worker count {} exceeds maximum {}",
                                count, settings.max_worker_count);
                        }
                    } else if count < current_workers {
                        if count >= settings.min_worker_count {
                            let decrease = current_workers - count;
                            info!("üìâ Decreasing worker count by {} to {}", decrease, count);
                            let _ = self.scale_down(decrease).await;
                        } else {
                            warn!("Requested worker count {} below minimum {}",
                                count, settings.min_worker_count);
                        }
                    }
                }
            }
            "min_batch_size" => {
                if let Ok(size) = value.parse::<usize>() {
                    let mut config = self.adaptive_batcher.config.clone();
                    config.min_batch_size = size.max(1);
                    if config.initial_batch_size < config.min_batch_size {
                        *self.adaptive_batcher.current_batch_size.write().await = config.min_batch_size;
                    }
                    self.record_metric("config.min_batch_size", size as f64).await;
                    info!("‚úÖ Min batch size updated to {}", size);
                }
            }
            "max_batch_size" => {
                if let Ok(size) = value.parse::<usize>() {
                    let mut config = self.adaptive_batcher.config.clone();
                    config.max_batch_size = size;
                    if config.initial_batch_size > config.max_batch_size {
                        *self.adaptive_batcher.current_batch_size.write().await = config.max_batch_size;
                    }
                    self.record_metric("config.max_batch_size", size as f64).await;
                    info!("‚úÖ Max batch size updated to {}", size);
                }
            }
            "target_latency_ms" => {
                if let Ok(ms) = value.parse::<u64>() {
                    let mut config = self.adaptive_batcher.config.clone();
                    config.target_latency = Duration::from_millis(ms);
                    self.record_metric("config.target_latency_ms", ms as f64).await;
                    info!("‚úÖ Target latency updated to {} ms", ms);
                }
            }
            "confidence_threshold" => {
                if let Ok(threshold) = value.parse::<f64>() {
                    let mut config = self.adaptive_batcher.config.clone();
                    config.confidence_threshold = threshold.clamp(0.0, 1.0);
                    self.record_metric("config.confidence_threshold", threshold).await;
                    info!("‚úÖ Confidence threshold updated to {:.2}", threshold);
                }
            }
            "enable_predictive_adaptation" => {
                if let Ok(enabled) = value.parse::<bool>() {
                    let mut config = self.adaptive_batcher.config.clone();
                    config.enable_predictive_adaptation = enabled;
                    self.record_metric("config.enable_predictive_adaptation", enabled as i64 as f64).await;
                    info!("‚úÖ Predictive adaptation {}", if enabled { "enabled" } else { "disabled" });
                }
            }
            "enable_auto_tuning" => {
                if let Ok(enabled) = value.parse::<bool>() {
                    let mut config = self.adaptive_batcher.config.clone();
                    config.enable_auto_tuning = enabled;
                    self.record_metric("config.enable_auto_tuning", enabled as i64 as f64).await;
                    info!("‚úÖ Auto tuning {}", if enabled { "enabled" } else { "disabled" });
                }
            }
            "prediction_horizon_sec" => {
                if let Ok(sec) = value.parse::<u64>() {
                    let mut config = self.adaptive_batcher.config.clone();
                    config.prediction_horizon = Duration::from_secs(sec);
                    self.record_metric("config.prediction_horizon_sec", sec as f64).await;
                    info!("‚úÖ Prediction horizon updated to {} seconds", sec);
                }
            }
            "smoothing_factor" => {
                if let Ok(factor) = value.parse::<f64>() {
                    let mut config = self.adaptive_batcher.config.clone();
                    config.smoothing_factor = factor.clamp(0.1, 0.9);
                    self.record_metric("config.smoothing_factor", factor).await;
                    info!("‚úÖ Smoothing factor updated to {:.2}", factor);
                }
            }
            _ => warn!("‚ö†Ô∏è Unknown parameter: {}", parameter),
        }
    }

    /// üö® –ê–≤–∞—Ä–∏–π–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
    async fn emergency_shutdown(&self, reason: String) {
        error!("üö® EMERGENCY SHUTDOWN: {}", reason);

        self.is_running.store(false, std::sync::atomic::Ordering::SeqCst);
        self.shutdown_components().await;

        self.record_metric("system.emergency_shutdown", 1.0).await;
    }

    /// üìä –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    async fn get_statistics(&self) {
        let stats = self.stats.read().await.clone();
        let status = self.get_system_status().await;

        info!("üìä System Statistics:");
        info!("  ‚îú‚îÄ Uptime: {:?}", stats.uptime);
        info!("  ‚îú‚îÄ Processed packets: {}", stats.total_packets_processed);
        info!("  ‚îú‚îÄ Data received: {} MB", stats.total_data_received / 1024 / 1024);
        info!("  ‚îú‚îÄ Data sent: {} MB", stats.total_data_sent / 1024 / 1024);
        info!("  ‚îú‚îÄ Active connections: {}", status.active_connections);
        info!("  ‚îú‚îÄ Active workers: {}", self.worker_pool.current_workers.load(std::sync::atomic::Ordering::SeqCst));
        info!("  ‚îú‚îÄ Avg processing time: {:?}", stats.avg_processing_time);
        info!("  ‚îú‚îÄ Peak throughput: {:.2} ops/s", stats.peak_throughput);
        info!("  ‚îú‚îÄ Crypto operations: {}", stats.crypto_operations);
        info!("  ‚îú‚îÄ Work steals: {}", stats.work_stealing_count);
        info!("  ‚îî‚îÄ Total errors: {}", stats.total_errors);
    }

    /// üîÑ –°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    async fn reset_statistics(&self) {
        info!("üîÑ Resetting system statistics...");

        let mut stats = self.stats.write().await;
        *stats = SystemStatistics {
            startup_time: stats.startup_time,
            ..Default::default()
        };

        self.metrics.clear();
        self.performance_counters.clear();
    }

    /// ‚öñÔ∏è –ü–ï–†–ï–ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ê –í–û–†–ö–ï–†–û–í
    async fn rebalance_workers(&self) {
        info!("‚öñÔ∏è Rebalancing workers...");

        let stats = self.work_stealing_dispatcher.get_advanced_stats().await;
        let imbalance = stats.imbalance;

        if imbalance > 0.3 {
            info!("‚öñÔ∏è High imbalance detected: {:.2}, forcing rebalance", imbalance);

            let current_loads: Vec<usize> = (0..self.work_stealing_dispatcher.worker_senders.len())
                .map(|i| self.work_stealing_dispatcher.worker_queues.get(&i).map(|q| *q).unwrap_or(0))
                .collect();

            let avg_load = current_loads.iter().sum::<usize>() as f64 / current_loads.len() as f64;

            for (worker_id, &load) in current_loads.iter().enumerate() {
                if load as f64 > avg_load * 1.5 {
                    debug!("‚öñÔ∏è Worker #{} overloaded ({} > {:.1}), stealing tasks",
                        worker_id, load, avg_load * 1.5);
                }
            }
        }

        self.record_metric("dispatcher.manual_rebalance", 1.0).await;
        self.record_metric("dispatcher.imbalance", imbalance).await;

        info!("‚úÖ Workers rebalanced, imbalance: {:.2} ‚Üí {:.2}",
            imbalance, self.work_stealing_dispatcher.get_advanced_stats().await.imbalance);
    }

    /// üìà –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–ï –í–í–ï–†–•
    async fn scale_up(&self, count: usize) -> Result<usize, BatchError> {
        info!("üìà Scaling up by {} workers", count);

        let _lock = self.scaling_lock.lock().await;

        let current_workers = self.worker_pool.current_workers.load(std::sync::atomic::Ordering::SeqCst);
        let settings = self.scaling_settings.read().await;

        if count == 0 {
            return Ok(0);
        }

        if current_workers >= settings.max_worker_count {
            warn!("‚ö†Ô∏è Cannot scale up: already at maximum workers ({})", current_workers);
            return Ok(0);
        }

        let added = self.worker_pool.add_workers(count, self.work_stealing_dispatcher.clone()).await?;

        if added > 0 {
            let mut new_settings = settings.clone();
            new_settings.last_scaling_time = Instant::now();
            *self.scaling_settings.write().await = new_settings;

            self.record_metric("scaling.scale_up", added as f64).await;
            self.record_metric("scaling.current_workers", (current_workers + added) as f64).await;

            info!("‚úÖ Scaled UP from {} to {} workers (added {})",
                current_workers, current_workers + added, added);
        }

        Ok(added)
    }

    /// üìâ –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–ï –í–ù–ò–ó
    async fn scale_down(&self, count: usize) -> Result<usize, BatchError> {
        info!("üìâ Scaling down by {} workers", count);

        let _lock = self.scaling_lock.lock().await;

        let current_workers = self.worker_pool.current_workers.load(std::sync::atomic::Ordering::SeqCst);
        let settings = self.scaling_settings.read().await;

        if count == 0 {
            return Ok(0);
        }

        if current_workers <= settings.min_worker_count {
            warn!("‚ö†Ô∏è Cannot scale down: already at minimum workers ({})", current_workers);
            return Ok(0);
        }

        let removed = self.worker_pool.remove_workers(count).await?;

        if removed > 0 {
            let mut new_settings = settings.clone();
            new_settings.last_scaling_time = Instant::now();
            *self.scaling_settings.write().await = new_settings;

            self.record_metric("scaling.scale_down", removed as f64).await;
            self.record_metric("scaling.current_workers", (current_workers - removed) as f64).await;

            info!("‚úÖ Scaled DOWN from {} to {} workers (removed {})",
                current_workers, current_workers - removed, removed);
        }

        Ok(removed)
    }

    /// ‚öôÔ∏è –û–ë–ù–û–í–õ–ï–ù–ò–ï –ù–ê–°–¢–†–û–ï–ö –°–ö–ï–ô–õ–ò–ù–ì–ê
    async fn update_scaling_settings(&self, settings: ScalingSettings) {
        let mut current = self.scaling_settings.write().await;

        // –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
        let mut validated = settings;
        if validated.min_worker_count < 1 {
            validated.min_worker_count = 1;
            warn!("‚ö†Ô∏è Min worker count adjusted to 1");
        }
        if validated.max_worker_count < validated.min_worker_count {
            validated.max_worker_count = validated.min_worker_count.max(256);
            warn!("‚ö†Ô∏è Max worker count adjusted to {}", validated.max_worker_count);
        }
        if validated.scaling_cooldown_seconds < 10 {
            validated.scaling_cooldown_seconds = 10;
            warn!("‚ö†Ô∏è Scaling cooldown adjusted to 10 seconds");
        }
        if validated.work_stealing_target_queue_size < 100 {
            validated.work_stealing_target_queue_size = 100;
            warn!("‚ö†Ô∏è Target queue size adjusted to 100");
        }
        if validated.buffer_pool_target_hit_rate <= 0.0 || validated.buffer_pool_target_hit_rate > 1.0 {
            validated.buffer_pool_target_hit_rate = 0.85;
            warn!("‚ö†Ô∏è Buffer pool target hit rate adjusted to 0.85");
        }
        if validated.crypto_processor_target_success_rate <= 0.0 || validated.crypto_processor_target_success_rate > 1.0 {
            validated.crypto_processor_target_success_rate = 0.99;
            warn!("‚ö†Ô∏è Crypto processor target success rate adjusted to 0.99");
        }
        if validated.connection_target_count < 1000 {
            validated.connection_target_count = 1000;
            warn!("‚ö†Ô∏è Connection target count adjusted to 1000");
        }

        // –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫ –≤–æ—Ä–∫–µ—Ä-–ø—É–ª—É
        if validated.min_worker_count != current.min_worker_count {
            let worker_pool = self.worker_pool.clone();
            let current_workers = worker_pool.current_workers.load(std::sync::atomic::Ordering::SeqCst);
            if current_workers < validated.min_worker_count {
                let increase = validated.min_worker_count - current_workers;
                drop(current);
                let _ = self.scale_up(increase).await;
                current = self.scaling_settings.write().await;
            }
        }

        if validated.max_worker_count != current.max_worker_count {
            let worker_pool = self.worker_pool.clone();
            let current_workers = worker_pool.current_workers.load(std::sync::atomic::Ordering::SeqCst);
            if current_workers > validated.max_worker_count {
                let decrease = current_workers - validated.max_worker_count;
                drop(current);
                let _ = self.scale_down(decrease).await;
                current = self.scaling_settings.write().await;
            }
        }

        *current = validated;

        // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        self.record_metric("scaling.min_workers", current.min_worker_count as f64).await;
        self.record_metric("scaling.max_workers", current.max_worker_count as f64).await;
        self.record_metric("scaling.auto_scaling_enabled", current.auto_scaling_enabled as i64 as f64).await;
        self.record_metric("scaling.cooldown_seconds", current.scaling_cooldown_seconds as f64).await;
        self.record_metric("scaling.target_queue_size", current.work_stealing_target_queue_size as f64).await;
        self.record_metric("scaling.target_hit_rate", current.buffer_pool_target_hit_rate).await;
        self.record_metric("scaling.target_success_rate", current.crypto_processor_target_success_rate).await;
        self.record_metric("scaling.target_connections", current.connection_target_count as f64).await;

        info!("‚öôÔ∏è Scaling settings updated:");
        info!("  ‚îú‚îÄ Min workers: {}", current.min_worker_count);
        info!("  ‚îú‚îÄ Max workers: {}", current.max_worker_count);
        info!("  ‚îú‚îÄ Auto scaling: {}", current.auto_scaling_enabled);
        info!("  ‚îú‚îÄ Cooldown: {}s", current.scaling_cooldown_seconds);
        info!("  ‚îú‚îÄ Target queue: {}", current.work_stealing_target_queue_size);
        info!("  ‚îú‚îÄ Target hit rate: {:.1}%", current.buffer_pool_target_hit_rate * 100.0);
        info!("  ‚îú‚îÄ Target success rate: {:.1}%", current.crypto_processor_target_success_rate * 100.0);
        info!("  ‚îî‚îÄ Target connections: {}", current.connection_target_count);
    }

    /// üìà –ó–∞–ø—É—Å–∫ —Å–±–æ—Ä—â–∏–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    async fn start_statistics_collector(&self) {
        let stats = self.stats.clone();
        let is_running = self.is_running.clone();

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(1));

            while is_running.load(std::sync::atomic::Ordering::Relaxed) {
                interval.tick().await;

                let mut stats_guard = stats.write().await;
                stats_guard.uptime = Instant::now().duration_since(stats_guard.startup_time);
            }
        });
    }

    /// üîÑ –ó–ê–ü–£–°–ö –û–ë–†–ê–ë–û–¢–ß–ò–ö–ê –ë–ê–¢–ß–ï–ô
    async fn start_batch_processor(&self) {
        let pending_batches = self.pending_batches.clone();
        let is_running = self.is_running.clone();
        let system = self.clone();

        tokio::spawn(async move {
            debug!("üîÑ Batch processor started");
            let mut interval = tokio::time::interval(Duration::from_millis(50));
            let mut batch_id_counter = 0u64;

            while is_running.load(std::sync::atomic::Ordering::Relaxed) {
                interval.tick().await;

                let batches_to_process = {
                    let mut batches = pending_batches.write().await;
                    if batches.is_empty() {
                        continue;
                    }

                    let now = Instant::now();
                    let optimal_size = system.adaptive_batcher.get_batch_size().await;

                    let (ready, not_ready): (Vec<_>, Vec<_>) = batches
                        .drain(..)
                        .partition(|batch| {
                            batch.deadline.map_or(true, |deadline| now >= deadline)
                                || batch.operations.len() >= optimal_size
                        });

                    *batches = not_ready;
                    ready
                };

                for mut batch in batches_to_process {
                    batch_id_counter += 1;
                    batch.id = batch_id_counter;
                    system.process_batch(batch).await;
                }
            }

            debug!("üëã Batch processor stopped");
        });
    }

    /// üì¶ –û–ë–†–ê–ë–û–¢–ö–ê –ë–ê–¢–ß–ê
    async fn process_batch(&self, batch: PendingBatch) {
        let start_time = Instant::now();
        let batch_size = batch.operations.len();
        let batch_id = batch.id;

        debug!("üîÑ Processing batch #{} with {} operations", batch_id, batch_size);

        let mut successful = 0;
        let mut processed_packets = Vec::new();

        for operation in batch.operations {
            match operation {
                BatchOperation::Encryption { session_id, data, key: _, nonce: _ } => {
                    if let Some(session) = self.session_manager.get_session(&session_id).await {
                        // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–Ω–∞—á–∞–ª–∞ –¥–µ—à–∏—Ñ—Ä—É–µ–º –ø–∞–∫–µ—Ç
                        match self.packet_processor.process_incoming_vec(&data, &session) {
                            Ok((packet_type, decrypted_payload)) => {
                                // ‚úÖ –ó–∞—Ç–µ–º –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ packet_service –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                                match self.packet_service.process_packet(
                                    session.clone(),
                                    packet_type,
                                    decrypted_payload,
                                    batch.source_addr,
                                ).await {
                                    Ok(processing_result) => {
                                        // ‚úÖ –®–∏—Ñ—Ä—É–µ–º –æ—Ç–≤–µ—Ç –æ—Ç packet_service
                                        match self.packet_processor.create_outgoing_vec(
                                            &session,
                                            processing_result.packet_type,
                                            &processing_result.response,
                                        ) {
                                            Ok(encrypted_response) => {
                                                successful += 1;

                                                let _ = self.writer.write(
                                                    batch.source_addr,
                                                    session_id,
                                                    Bytes::from(encrypted_response),
                                                    processing_result.priority,
                                                    processing_result.packet_type == 0x01, // flush –¥–ª—è Ping
                                                ).await;

                                                debug!("‚úÖ Processed packet type 0x{:02x} through packet_service", packet_type);
                                            }
                                            Err(e) => {
                                                debug!("‚ùå Encryption failed: {}", e);
                                            }
                                        }
                                    }
                                    Err(e) => {
                                        debug!("‚ùå Packet service processing failed: {}", e);
                                    }
                                }
                            }
                            Err(e) => {
                                debug!("‚ùå Decryption failed: {}", e);
                            }
                        }
                    }
                }

                BatchOperation::Decryption { session_id, data, key: _, nonce: _ } => {
                    let packet_type_byte = if !data.is_empty() { data[0] } else { 0 };

                    if !is_packet_supported(packet_type_byte) {
                        debug!("‚ö†Ô∏è Unsupported packet type for decryption: 0x{:02x}", packet_type_byte);
                        continue;
                    }

                    if let Some(session) = self.session_manager.get_session(&session_id).await {
                        match self.packet_processor.process_incoming_vec(&data, &session) {
                            Ok((decoded_type, _)) => {
                                if decoded_type == packet_type_byte {
                                    successful += 1;
                                    processed_packets.push((packet_type_byte, true));
                                    debug!("‚úÖ Decrypted packet type 0x{:02x}", packet_type_byte);
                                }
                            }
                            Err(e) => {
                                debug!("‚ùå Decryption failed for packet type 0x{:02x}: {}", packet_type_byte, e);
                                processed_packets.push((packet_type_byte, false));
                            }
                        }
                    }
                }

                BatchOperation::Hashing { data, key } => {
                    if let Some(key) = key {
                        let keys = vec![key; 1];
                        let inputs = vec![data.to_vec()];
                        let hashes = self.blake3_accelerator.hash_keyed_batch(&keys, &inputs).await;
                        if !hashes.is_empty() {
                            successful += 1;
                        }
                    }
                }

                BatchOperation::Processing { session_id, data, processor_type } => {
                    let packet_type_byte = if !data.is_empty() { data[0] } else { 0 };

                    if !is_packet_supported(packet_type_byte) {
                        debug!("‚ö†Ô∏è Unsupported packet type for processing: 0x{:02x}", packet_type_byte);
                        continue;
                    }

                    match processor_type {
                        ProcessorType::Accelerated => {
                            let _priority = get_packet_priority(packet_type_byte).unwrap_or(Priority::Normal);

                            if let Some(session) = self.session_manager.get_session(&session_id).await {
                                match self.packet_processor.create_outgoing_vec(&session, packet_type_byte, &data) {
                                    Ok(_encrypted) => {
                                        successful += 1;
                                        processed_packets.push((packet_type_byte, true));
                                    }
                                    Err(e) => {
                                        debug!("‚ùå Processing failed for packet type 0x{:02x}: {}", packet_type_byte, e);
                                        processed_packets.push((packet_type_byte, false));
                                    }
                                }
                            }
                        }
                        _ => {
                            successful += 1;
                            processed_packets.push((packet_type_byte, true));
                        }
                    }
                }
            }
        }

        let success_rate = if batch_size > 0 {
            successful as f64 / batch_size as f64
        } else {
            1.0
        };

        let processing_time = start_time.elapsed();

        // ‚úÖ –õ–û–ì–ò–†–£–ï–ú –°–¢–ê–¢–ò–°–¢–ò–ö–£ –ü–û –¢–ò–ü–ê–ú –ü–ê–ö–ï–¢–û–í
        let mut packet_stats = HashMap::new();
        for (packet_type, success) in processed_packets {
            *packet_stats.entry(packet_type).or_insert((0, 0)) = (
                packet_stats.get(&packet_type).map(|(s, _)| s + 1).unwrap_or(1),
                if success { 1 } else { 0 }
            );
        }

        if !packet_stats.is_empty() {
            debug!("üìä Batch #{} packet types:", batch_id);
            for (packet_type, (total, successful_count)) in packet_stats {
                if let Some(info) = get_packet_info(packet_type) {
                    debug!("  - 0x{:02x}: {}/{} ({:.1}%) - {}",
                       packet_type, successful_count, total,
                       (successful_count as f64 / total as f64) * 100.0,
                       info.description);
                }
            }
        }

        self.adaptive_batcher.record_batch_execution(
            batch_size,
            processing_time,
            success_rate,
            self.pending_batches.read().await.len(),
        ).await;

        {
            let mut stats = self.stats.write().await;
            stats.total_batches_processed += 1;
            stats.crypto_operations += successful as u64;
        }

        let event = SystemEvent::BatchCompleted {
            batch_id,
            size: batch_size,
            processing_time,
            success_rate,
        };

        let _ = self.event_tx.send(event).await;

        debug!("‚úÖ Batch #{} completed: {}/{} successful, {:.1}% in {:?}",
        batch_id, successful, batch_size, success_rate * 100.0, processing_time);
    }

    /// üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    async fn shutdown_components(&self) {
        info!("üõë Shutting down components...");

        self.work_stealing_dispatcher.shutdown().await;
        self.crypto_processor.shutdown().await;
        self.reader.shutdown().await;
        self.writer.shutdown().await;

        info!("‚úÖ All components shut down");
    }

    /// üîó –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    pub async fn register_connection(
        &self,
        source_addr: std::net::SocketAddr,
        session_id: Vec<u8>,
        read_stream: Box<dyn tokio::io::AsyncRead + Unpin + Send + Sync>,
        write_stream: Box<dyn tokio::io::AsyncWrite + Unpin + Send + Sync>,
    ) -> Result<(), BatchError> {
        debug!("üîó Registering connection: {} -> {}", source_addr, hex::encode(&session_id));

        self.reader.register_connection(
            source_addr,
            session_id.clone(),
            read_stream,
        ).await?;

        self.writer.register_connection(
            source_addr,
            session_id.clone(),
            write_stream,
        ).await?;

        let event = SystemEvent::ConnectionOpened {
            addr: source_addr,
            session_id,
        };

        let _ = self.event_tx.send(event).await;

        Ok(())
    }

    /// üìä –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã
    pub async fn get_system_status(&self) -> SystemStatus {
        let stats = self.stats.read().await.clone();
        let connections = self.active_connections.read().await;
        let settings = self.scaling_settings.read().await.clone();

        let batch_metrics = self.adaptive_batcher.get_metrics().await;
        let qos_stats = self.qos_manager.get_statistics().await;
        let qos_quotas = self.qos_manager.get_quotas().await;
        let qos_utilization = self.qos_manager.get_utilization().await;
        let circuit_stats = self.circuit_breaker_manager.get_all_stats().await;
        let dispatcher_stats = self.work_stealing_dispatcher.get_advanced_stats().await;
        let current_workers = self.worker_pool.current_workers.load(std::sync::atomic::Ordering::SeqCst);

        SystemStatus {
            timestamp: Instant::now(),
            is_running: self.is_running.load(std::sync::atomic::Ordering::Relaxed),
            statistics: stats,
            active_connections: connections.len(),
            active_workers: current_workers,
            pending_tasks: self.pending_batches.read().await.len(),
            memory_usage: MemoryUsage {
                total: 0,
                used: 0,
                free: 0,
                buffer_pool: self.buffer_pool.get_detailed_stats()
                    .values()
                    .map(|s| s.memory_mb as usize * 1024 * 1024)
                    .sum(),
                crypto_pool: 0,
                connections: connections.len(),
                session_cache: self.session_cache.read().await.len(),
            },
            throughput: self.calculate_throughput().await,
            scaling_settings: settings,
            batch_metrics,
            qos_stats,
            qos_quotas,
            qos_utilization,
            circuit_stats,
            dispatcher_stats,
        }
    }

    /// üìà –†–∞—Å—á–µ—Ç –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
    async fn calculate_throughput(&self) -> ThroughputMetrics {
        let stats = self.stats.read().await;
        let uptime = stats.uptime.as_secs_f64().max(1.0);

        ThroughputMetrics {
            packets_per_second: stats.total_packets_processed as f64 / uptime,
            bytes_per_second: stats.total_data_received as f64 / uptime,
            operations_per_second: stats.total_batches_processed as f64 / uptime,
            avg_batch_size: self.adaptive_batcher.get_metrics().await.avg_batch_size,
            latency_p50: stats.avg_processing_time,
            latency_p95: Duration::from_nanos((stats.avg_processing_time.as_nanos() as f64 * 1.5) as u64),
            latency_p99: Duration::from_nanos((stats.avg_processing_time.as_nanos() as f64 * 2.0) as u64),
        }
    }

    /// üìù –ó–∞–ø–∏—Å—å –º–µ—Ç—Ä–∏–∫–∏
    async fn record_metric(&self, name: &str, value: f64) {
        self.metrics.insert(name.to_string(), MetricValue::Float(value));
        self.metrics_tracing.record_metric(name, value);

        if let Some(mut counter) = self.performance_counters.get_mut(name) {
            counter.update(value);
        } else {
            let mut counter = PerformanceCounter::new(name.to_string(), 60);
            counter.update(value);
            self.performance_counters.insert(name.to_string(), counter);
        }
    }

    /// üìä –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
    async fn get_metric(&self, name: &str) -> Option<f64> {
        self.metrics.get(name).and_then(|m| {
            if let MetricValue::Float(v) = m.value() {
                Some(*v)
            } else {
                None
            }
        })
    }

    /// üì¶ –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
    pub fn get_dispatcher(&self) -> Arc<WorkStealingDispatcher> {
        self.work_stealing_dispatcher.clone()
    }

    /// üì¶ –ü–æ–ª—É—á–µ–Ω–∏–µ QoS –º–µ–Ω–µ–¥–∂–µ—Ä–∞
    pub fn get_qos_manager(&self) -> Arc<QosManager> {
        self.qos_manager.clone()
    }

    /// üì¶ –ü–æ–ª—É—á–µ–Ω–∏–µ Adaptive Batcher
    pub fn get_adaptive_batcher(&self) -> Arc<AdaptiveBatcher> {
        self.adaptive_batcher.clone()
    }

    /// üì¶ –ü–æ–ª—É—á–µ–Ω–∏–µ Circuit Breaker Manager
    pub fn get_circuit_breaker_manager(&self) -> Arc<CircuitBreakerManager> {
        self.circuit_breaker_manager.clone()
    }

    /// üì¶ –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤–æ—Ä–∫–µ—Ä–æ–≤
    pub fn get_current_workers(&self) -> usize {
        self.worker_pool.current_workers.load(std::sync::atomic::Ordering::SeqCst)
    }

    /// üì¶ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ –±–∞—Ç—á
    pub async fn add_to_batch(&self, operation: BatchOperation, source_addr: std::net::SocketAddr, priority: Priority) {
        let mut pending = self.pending_batches.write().await;

        let batch = pending.iter_mut().find(|b|
            b.source_addr == source_addr &&
                b.priority == priority &&
                b.deadline.map_or(true, |d| d > Instant::now())
        );

        if let Some(batch) = batch {
            batch.operations.push(operation);
        } else {
            pending.push(PendingBatch {
                id: 0,
                operations: vec![operation],
                priority,
                source_addr,
                created_at: Instant::now(),
                deadline: Some(Instant::now() + Duration::from_millis(100)),
                retry_count: 0,
            });
        }
    }
}

/// ============= –°–¢–†–£–ö–¢–£–†–´ –î–ê–ù–ù–´–• =============

/// –°–æ–±—ã—Ç–∏—è —Å–∏—Å—Ç–µ–º—ã
#[derive(Debug, Clone)]
pub enum SystemEvent {
    DataReceived {
        session_id: Vec<u8>,
        data: Bytes,
        source_addr: std::net::SocketAddr,
        priority: Priority,
        timestamp: Instant,
    },
    DataProcessed {
        session_id: Vec<u8>,
        result: ProcessResult,
        processing_time: Duration,
        worker_id: Option<usize>,
    },
    ConnectionOpened {
        addr: std::net::SocketAddr,
        session_id: Vec<u8>,
    },
    ConnectionClosed {
        addr: std::net::SocketAddr,
        session_id: Vec<u8>,
        reason: String,
    },
    BatchCompleted {
        batch_id: u64,
        size: usize,
        processing_time: Duration,
        success_rate: f64,
    },
    ErrorOccurred {
        error: String,
        context: String,
        severity: ErrorSeverity,
    },
}

/// –ö–æ–º–∞–Ω–¥—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–æ–π
#[derive(Debug, Clone)]
pub enum SystemCommand {
    StartProcessing,
    PauseProcessing,
    ResumeProcessing,
    StopProcessing,
    FlushBuffers,
    ClearCaches,
    AdjustConfig {
        parameter: String,
        value: String,
    },
    EmergencyShutdown {
        reason: String,
    },
    GetStatistics,
    ResetStatistics,
    RebalanceWorkers,
    ScaleUp {
        count: usize,
    },
    ScaleDown {
        count: usize,
    },
    UpdateScalingSettings {
        settings: ScalingSettings,
    },
}

/// –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
#[derive(Debug, Clone)]
pub struct SystemStatus {
    pub timestamp: Instant,
    pub is_running: bool,
    pub statistics: SystemStatistics,
    pub active_connections: usize,
    pub active_workers: usize,
    pub pending_tasks: usize,
    pub memory_usage: MemoryUsage,
    pub throughput: ThroughputMetrics,
    pub scaling_settings: ScalingSettings,
    pub batch_metrics: BatchMetrics,
    pub qos_stats: QosStatistics,
    pub qos_quotas: (f64, f64, f64),
    pub qos_utilization: (f64, f64, f64),
    pub circuit_stats: Vec<CircuitBreakerStats>,
    pub dispatcher_stats: DispatcherAdvancedStats,
}

/// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã
#[derive(Debug, Clone)]
pub struct SystemStatistics {
    pub total_data_received: u64,
    pub total_data_sent: u64,
    pub total_packets_processed: u64,
    pub total_batches_processed: u64,
    pub total_errors: u64,
    pub total_connections: u64,
    pub avg_processing_time: Duration,
    pub peak_throughput: f64,
    pub buffer_hit_rate: f64,
    pub crypto_operations: u64,
    pub work_stealing_count: u64,
    pub startup_time: Instant,
    pub uptime: Duration,
}

impl Default for SystemStatistics {
    fn default() -> Self {
        Self {
            total_data_received: 0,
            total_data_sent: 0,
            total_packets_processed: 0,
            total_batches_processed: 0,
            total_errors: 0,
            total_connections: 0,
            avg_processing_time: Duration::from_secs(0),
            peak_throughput: 0.0,
            buffer_hit_rate: 0.0,
            crypto_operations: 0,
            work_stealing_count: 0,
            startup_time: Instant::now(),
            uptime: Duration::from_secs(0),
        }
    }
}

/// –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∫–µ–π–ª–∏–Ω–≥–∞
#[derive(Debug, Clone)]
pub struct ScalingSettings {
    pub buffer_pool_target_hit_rate: f64,
    pub crypto_processor_target_success_rate: f64,
    pub work_stealing_target_queue_size: usize,
    pub connection_target_count: usize,
    pub min_worker_count: usize,
    pub max_worker_count: usize,
    pub auto_scaling_enabled: bool,
    pub scaling_cooldown_seconds: u64,
    pub last_scaling_time: Instant,
}

impl Default for ScalingSettings {
    fn default() -> Self {
        Self {
            buffer_pool_target_hit_rate: 0.85,
            crypto_processor_target_success_rate: 0.99,
            work_stealing_target_queue_size: 1000,
            connection_target_count: 10000,
            min_worker_count: 4,
            max_worker_count: 256,
            auto_scaling_enabled: true,
            scaling_cooldown_seconds: 60,
            last_scaling_time: Instant::now(),
        }
    }
}

/// –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–∏
#[derive(Debug, Clone)]
pub struct ConnectionInfo {
    pub addr: std::net::SocketAddr,
    pub session_id: Vec<u8>,
    pub opened_at: Instant,
    pub last_activity: Instant,
    pub bytes_received: u64,
    pub bytes_sent: u64,
    pub priority: Priority,
    pub is_active: bool,
    pub worker_assigned: Option<usize>,
}

/// –ö—ç—à —Å–µ—Å—Å–∏–∏
#[derive(Debug, Clone)]
pub struct SessionCacheEntry {
    pub session_id: Vec<u8>,
    pub last_used: Instant,
    pub access_count: u64,
    pub data: Bytes,
    pub metadata: HashMap<String, String>,
}

/// –û–∂–∏–¥–∞—é—â–∏–π –±–∞—Ç—á
#[derive(Debug, Clone)]
pub struct PendingBatch {
    pub id: u64,
    pub operations: Vec<BatchOperation>,
    pub priority: Priority,
    pub source_addr: std::net::SocketAddr,
    pub created_at: Instant,
    pub deadline: Option<Instant>,
    pub retry_count: u32,
}

/// –û–ø–µ—Ä–∞—Ü–∏—è –±–∞—Ç—á–∞
#[derive(Debug, Clone)]
pub enum BatchOperation {
    Encryption {
        session_id: Vec<u8>,
        data: Bytes,
        key: [u8; 32],
        nonce: [u8; 12],
    },
    Decryption {
        session_id: Vec<u8>,
        data: Bytes,
        key: [u8; 32],
        nonce: [u8; 12],
    },
    Hashing {
        data: Bytes,
        key: Option<[u8; 32]>,
    },
    Processing {
        session_id: Vec<u8>,
        data: Bytes,
        processor_type: ProcessorType,
    },
}

/// –¢–∏–ø –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ProcessorType {
    Standard,
    Accelerated,
    Optimized,
    WorkStealing,
}

/// –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
#[derive(Debug, Clone)]
pub struct ProcessResult {
    pub success: bool,
    pub data: Option<Bytes>,
    pub error: Option<String>,
    pub metadata: HashMap<String, String>,
}

/// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
#[derive(Debug, Clone)]
pub struct MemoryUsage {
    pub total: usize,
    pub used: usize,
    pub free: usize,
    pub buffer_pool: usize,
    pub crypto_pool: usize,
    pub connections: usize,
    pub session_cache: usize,
}

/// –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
#[derive(Debug, Clone)]
pub struct ThroughputMetrics {
    pub packets_per_second: f64,
    pub bytes_per_second: f64,
    pub operations_per_second: f64,
    pub avg_batch_size: f64,
    pub latency_p50: Duration,
    pub latency_p95: Duration,
    pub latency_p99: Duration,
}

/// –°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å –æ—à–∏–±–∫–∏
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ErrorSeverity {
    Low = 0,
    Medium = 1,
    High = 2,
    Critical = 3,
}

/// –ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
#[derive(Debug, Clone)]
pub enum MetricValue {
    Integer(i64),
    Float(f64),
    Duration(Duration),
    String(String),
    Boolean(bool),
}

/// –°—á–µ—Ç—á–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
#[derive(Debug, Clone)]
pub struct PerformanceCounter {
    pub name: String,
    pub value: f64,
    pub timestamp: Instant,
    pub window_size: usize,
    pub values: VecDeque<f64>,
}

impl PerformanceCounter {
    pub fn new(name: String, window_size: usize) -> Self {
        Self {
            name,
            value: 0.0,
            timestamp: Instant::now(),
            window_size,
            values: VecDeque::with_capacity(window_size),
        }
    }

    pub fn update(&mut self, value: f64) {
        self.value = value;
        self.timestamp = Instant::now();
        self.values.push_back(value);
        if self.values.len() > self.window_size {
            self.values.pop_front();
        }
    }

    pub fn average(&self) -> f64 {
        if self.values.is_empty() {
            return 0.0;
        }
        self.values.iter().sum::<f64>() / self.values.len() as f64
    }
}

impl Clone for IntegratedBatchSystem {
    fn clone(&self) -> Self {
        Self {
            config: self.config.clone(),
            reader: self.reader.clone(),
            writer: self.writer.clone(),
            work_stealing_dispatcher: self.work_stealing_dispatcher.clone(),
            crypto_processor: self.crypto_processor.clone(),
            buffer_pool: self.buffer_pool.clone(),
            chacha20_accelerator: self.chacha20_accelerator.clone(),
            blake3_accelerator: self.blake3_accelerator.clone(),
            circuit_breaker_manager: self.circuit_breaker_manager.clone(),
            qos_manager: self.qos_manager.clone(),
            adaptive_batcher: self.adaptive_batcher.clone(),
            metrics_tracing: self.metrics_tracing.clone(),
            packet_service: self.packet_service.clone(),
            packet_processor: self.packet_processor.clone(),
            session_manager: self.session_manager.clone(),
            crypto: self.crypto.clone(),
            event_tx: self.event_tx.clone(),
            event_rx: self.event_rx.clone(),
            command_tx: self.command_tx.clone(),
            is_running: self.is_running.clone(),
            is_initialized: self.is_initialized.clone(),
            startup_time: self.startup_time,
            stats: self.stats.clone(),
            metrics: self.metrics.clone(),
            pending_batches: self.pending_batches.clone(),
            active_connections: self.active_connections.clone(),
            session_cache: self.session_cache.clone(),
            scaling_settings: self.scaling_settings.clone(),
            performance_counters: self.performance_counters.clone(),
            worker_pool: self.worker_pool.clone(),
            scaling_lock: self.scaling_lock.clone(),
        }
    }
}

use std::collections::VecDeque;